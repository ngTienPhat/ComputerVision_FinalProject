{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: OSNet x10, data_aug: color jitter, loss: softmax, epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_DIR = \"\" # input your weight directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show configuration\n",
      "adam:\n",
      "  beta1: 0.9\n",
      "  beta2: 0.999\n",
      "cuhk03:\n",
      "  classic_split: False\n",
      "  labeled_images: False\n",
      "  use_metric_cuhk03: False\n",
      "data:\n",
      "  combineall: False\n",
      "  height: 256\n",
      "  load_train_targets: False\n",
      "  norm_mean: [0.485, 0.456, 0.406]\n",
      "  norm_std: [0.229, 0.224, 0.225]\n",
      "  root: datasets\n",
      "  save_dir: result/log_ep200_coljit_softmax\n",
      "  sources: ['market1501']\n",
      "  split_id: 0\n",
      "  targets: ['market1501']\n",
      "  transforms: ['random_flip', 'color_jitter']\n",
      "  type: image\n",
      "  width: 128\n",
      "  workers: 4\n",
      "loss:\n",
      "  name: softmax\n",
      "  softmax:\n",
      "    label_smooth: True\n",
      "  triplet:\n",
      "    margin: 0.3\n",
      "    weight_t: 1.0\n",
      "    weight_x: 0.0\n",
      "market1501:\n",
      "  use_500k_distractors: False\n",
      "model:\n",
      "  load_weights: log/log_ep200_coljit_softmax/log_ep200_coljit_softmax/log/osnetx1_0_market_200ep_colorjitter/model/model.pth.tar-200\n",
      "  name: osnet_x1_0\n",
      "  pretrained: True\n",
      "  resume: \n",
      "rmsprop:\n",
      "  alpha: 0.99\n",
      "sampler:\n",
      "  num_instances: 4\n",
      "  train_sampler: RandomSampler\n",
      "  train_sampler_t: RandomSampler\n",
      "sgd:\n",
      "  dampening: 0.0\n",
      "  momentum: 0.9\n",
      "  nesterov: False\n",
      "test:\n",
      "  batch_size: 300\n",
      "  dist_metric: euclidean\n",
      "  eval_freq: 100\n",
      "  evaluate: True\n",
      "  normalize_feature: False\n",
      "  ranks: [1, 5, 10, 20]\n",
      "  rerank: False\n",
      "  start_eval: 0\n",
      "  visrank: True\n",
      "  visrank_topk: 10\n",
      "train:\n",
      "  base_lr_mult: 0.1\n",
      "  batch_size: 64\n",
      "  fixbase_epoch: 10\n",
      "  gamma: 0.1\n",
      "  lr: 0.0015\n",
      "  lr_scheduler: cosine\n",
      "  max_epoch: 200\n",
      "  new_layers: ['classifier']\n",
      "  open_layers: ['classifier']\n",
      "  optim: amsgrad\n",
      "  print_freq: 100\n",
      "  seed: 1\n",
      "  staged_lr: False\n",
      "  start_epoch: 0\n",
      "  stepsize: [20]\n",
      "  weight_decay: 0.0005\n",
      "use_gpu: True\n",
      "video:\n",
      "  pooling_method: avg\n",
      "  sample_method: evenly\n",
      "  seq_len: 15\n",
      "\n",
      "Collecting env info ...\n",
      "** System info **\n",
      "PyTorch version: 1.5.1\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.2\n",
      "\n",
      "OS: Ubuntu 16.04.6 LTS\n",
      "GCC version: (Ubuntu 5.5.0-12ubuntu5~16.04) 5.5.0 20171010\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.6\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 7.5.17\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce GTX 1080 Ti\n",
      "GPU 1: GeForce GTX 1080 Ti\n",
      "\n",
      "Nvidia driver version: 440.64.00\n",
      "cuDNN version: Probably one of the following:\n",
      "/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6\n",
      "/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.7\n",
      "/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so.7\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.19.0\n",
      "[pip3] torch==1.5.1\n",
      "[pip3] torchreid==1.2.3\n",
      "[pip3] torchvision==0.6.1\n",
      "[conda] torch                     1.5.1                    pypi_0    pypi\n",
      "[conda] torchreid                 1.2.3                     dev_0    <develop>\n",
      "[conda] torchvision               0.6.1                    pypi_0    pypi\n",
      "        Pillow (7.2.0)\n",
      "\n",
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ color jitter\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n",
      "Building model: osnet_x1_0\n",
      "Successfully loaded imagenet pretrained weights from \"/home/ntphat/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Model complexity: params=2,193,616 flops=978,878,352\n",
      "Successfully loaded pretrained weights from \"log/log_ep200_coljit_softmax/log_ep200_coljit_softmax/log/osnetx1_0_market_200ep_colorjitter/model/model.pth.tar-200\"\n",
      "Building softmax-engine for image-reid\n",
      "##### Evaluating market1501 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 3368-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 15913-by-512 matrix\n",
      "Speed: 0.0833 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha)\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 81.5%\n",
      "CMC curve\n",
      "Rank-1  : 93.5%\n",
      "Rank-5  : 97.5%\n",
      "Rank-10 : 98.2%\n",
      "Rank-20 : 98.9%\n",
      "# query: 3368\n",
      "# gallery 15913\n",
      "Visualizing top-10 ranks ...\n",
      "- done 100/3368\n",
      "- done 200/3368\n",
      "- done 300/3368\n",
      "- done 400/3368\n",
      "- done 500/3368\n",
      "- done 600/3368\n",
      "- done 700/3368\n",
      "- done 800/3368\n",
      "- done 900/3368\n",
      "- done 1000/3368\n",
      "- done 1100/3368\n",
      "- done 1200/3368\n",
      "- done 1300/3368\n",
      "- done 1400/3368\n",
      "- done 1500/3368\n",
      "- done 1600/3368\n",
      "- done 1700/3368\n",
      "- done 1800/3368\n",
      "- done 1900/3368\n",
      "- done 2000/3368\n",
      "- done 2100/3368\n",
      "- done 2200/3368\n",
      "- done 2300/3368\n",
      "- done 2400/3368\n",
      "- done 2500/3368\n",
      "- done 2600/3368\n",
      "- done 2700/3368\n",
      "- done 2800/3368\n",
      "- done 2900/3368\n",
      "- done 3000/3368\n",
      "- done 3100/3368\n",
      "- done 3200/3368\n",
      "- done 3300/3368\n",
      "Done. Images have been saved to \"result/log_ep200_coljit_softmax/visrank_market1501\" ...\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "!python scripts/main.py \\\n",
    "--config-file \"configs/osnetx10_softmax_256x128_amsgrad_cosine_randflip_coljit.yaml\" \\\n",
    "--root \"datasets\" \\\n",
    "model.load_weights $WEIGHT_DIR \\\n",
    "test.evaluate True \\\n",
    "test.visrank True \\\n",
    "data.save_dir \"result/log_ep200_coljit_softmax\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n",
      "Successfully loaded imagenet pretrained weights from \"/home/ntphat/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Successfully loaded pretrained weights from \"log/log_ep200_coljit_softmax/log_ep200_coljit_softmax/log/osnetx1_0_market_200ep_colorjitter/model/model.pth.tar-200\"\n",
      "Visualizing activation maps for market1501 ...\n",
      "- done batch 10/34\n",
      "- done batch 20/34\n",
      "- done batch 30/34\n"
     ]
    }
   ],
   "source": [
    "# Visualize activation map\n",
    "!python tools/visualize_actmap.py \\\n",
    "--root \"datasets\" \\\n",
    "--save-dir \"result/log_ep200_coljit_softmax\" \\\n",
    "--weights $WEIGHT_DIR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: OSNet x10, data_aug: color jitter, loss: triplet, epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show configuration\n",
      "adam:\n",
      "  beta1: 0.9\n",
      "  beta2: 0.999\n",
      "cuhk03:\n",
      "  classic_split: False\n",
      "  labeled_images: False\n",
      "  use_metric_cuhk03: False\n",
      "data:\n",
      "  combineall: False\n",
      "  height: 256\n",
      "  load_train_targets: False\n",
      "  norm_mean: [0.485, 0.456, 0.406]\n",
      "  norm_std: [0.229, 0.224, 0.225]\n",
      "  root: datasets\n",
      "  save_dir: result/log_ep200_coljit_triplet\n",
      "  sources: ['market1501']\n",
      "  split_id: 0\n",
      "  targets: ['market1501']\n",
      "  transforms: ['random_flip', 'color_jitter']\n",
      "  type: image\n",
      "  width: 128\n",
      "  workers: 4\n",
      "loss:\n",
      "  name: triplet\n",
      "  softmax:\n",
      "    label_smooth: True\n",
      "  triplet:\n",
      "    margin: 0.3\n",
      "    weight_t: 1.0\n",
      "    weight_x: 0.0\n",
      "market1501:\n",
      "  use_500k_distractors: False\n",
      "model:\n",
      "  load_weights: log/log_ep200_coljit_triplet/log/osnetx10_market_200ep_colorjitter_triplet/model/model.pth.tar-200\n",
      "  name: osnet_x1_0\n",
      "  pretrained: True\n",
      "  resume: \n",
      "rmsprop:\n",
      "  alpha: 0.99\n",
      "sampler:\n",
      "  num_instances: 4\n",
      "  train_sampler: RandomSampler\n",
      "  train_sampler_t: RandomSampler\n",
      "sgd:\n",
      "  dampening: 0.0\n",
      "  momentum: 0.9\n",
      "  nesterov: False\n",
      "test:\n",
      "  batch_size: 300\n",
      "  dist_metric: euclidean\n",
      "  eval_freq: 100\n",
      "  evaluate: True\n",
      "  normalize_feature: False\n",
      "  ranks: [1, 5, 10, 20]\n",
      "  rerank: False\n",
      "  start_eval: 0\n",
      "  visrank: True\n",
      "  visrank_topk: 10\n",
      "train:\n",
      "  base_lr_mult: 0.1\n",
      "  batch_size: 64\n",
      "  fixbase_epoch: 10\n",
      "  gamma: 0.1\n",
      "  lr: 0.0015\n",
      "  lr_scheduler: cosine\n",
      "  max_epoch: 200\n",
      "  new_layers: ['classifier']\n",
      "  open_layers: ['classifier']\n",
      "  optim: amsgrad\n",
      "  print_freq: 100\n",
      "  seed: 1\n",
      "  staged_lr: False\n",
      "  start_epoch: 0\n",
      "  stepsize: [20]\n",
      "  weight_decay: 0.0005\n",
      "use_gpu: True\n",
      "video:\n",
      "  pooling_method: avg\n",
      "  sample_method: evenly\n",
      "  seq_len: 15\n",
      "\n",
      "Collecting env info ...\n",
      "** System info **\n",
      "PyTorch version: 1.5.1\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.2\n",
      "\n",
      "OS: Ubuntu 16.04.6 LTS\n",
      "GCC version: (Ubuntu 5.5.0-12ubuntu5~16.04) 5.5.0 20171010\n",
      "CMake version: version 3.5.1\n",
      "\n",
      "Python version: 3.6\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 7.5.17\n",
      "GPU models and configuration: \n",
      "GPU 0: GeForce GTX 1080 Ti\n",
      "GPU 1: GeForce GTX 1080 Ti\n",
      "\n",
      "Nvidia driver version: 440.64.00\n",
      "cuDNN version: Probably one of the following:\n",
      "/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.6\n",
      "/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.7\n",
      "/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudnn.so.7\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.19.0\n",
      "[pip3] torch==1.5.1\n",
      "[pip3] torchreid==1.2.3\n",
      "[pip3] torchvision==0.6.1\n",
      "[conda] torch                     1.5.1                    pypi_0    pypi\n",
      "[conda] torchreid                 1.2.3                     dev_0    <develop>\n",
      "[conda] torchvision               0.6.1                    pypi_0    pypi\n",
      "        Pillow (7.2.0)\n",
      "\n",
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ color jitter\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n",
      "Building model: osnet_x1_0\n",
      "Successfully loaded imagenet pretrained weights from \"/home/ntphat/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Model complexity: params=2,193,616 flops=978,878,352\n",
      "Successfully loaded pretrained weights from \"log/log_ep200_coljit_triplet/log/osnetx10_market_200ep_colorjitter_triplet/model/model.pth.tar-200\"\n",
      "Building triplet-engine for image-reid\n",
      "##### Evaluating market1501 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 3368-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 15913-by-512 matrix\n",
      "Speed: 0.0844 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha)\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 80.7%\n",
      "CMC curve\n",
      "Rank-1  : 93.0%\n",
      "Rank-5  : 97.0%\n",
      "Rank-10 : 98.2%\n",
      "Rank-20 : 98.8%\n",
      "# query: 3368\n",
      "# gallery 15913\n",
      "Visualizing top-10 ranks ...\n",
      "- done 100/3368\n",
      "- done 200/3368\n",
      "- done 300/3368\n",
      "- done 400/3368\n",
      "- done 500/3368\n",
      "- done 600/3368\n",
      "- done 700/3368\n",
      "- done 800/3368\n",
      "- done 900/3368\n",
      "- done 1000/3368\n",
      "- done 1100/3368\n",
      "- done 1200/3368\n",
      "- done 1300/3368\n",
      "- done 1400/3368\n",
      "- done 1500/3368\n",
      "- done 1600/3368\n",
      "- done 1700/3368\n",
      "- done 1800/3368\n",
      "- done 1900/3368\n",
      "- done 2000/3368\n",
      "- done 2100/3368\n",
      "- done 2200/3368\n",
      "- done 2300/3368\n",
      "- done 2400/3368\n",
      "- done 2500/3368\n",
      "- done 2600/3368\n",
      "- done 2700/3368\n",
      "- done 2800/3368\n",
      "- done 2900/3368\n",
      "- done 3000/3368\n",
      "- done 3100/3368\n",
      "- done 3200/3368\n",
      "- done 3300/3368\n",
      "Done. Images have been saved to \"result/log_ep200_coljit_triplet/visrank_market1501\" ...\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "!python scripts/main.py \\\n",
    "--config-file \"configs/osnetx10_softmax_256x128_amsgrad_cosine_randflip_coljit.yaml\" \\\n",
    "--root \"datasets\" \\\n",
    "model.load_weights $WEIGHT_DIR \\\n",
    "test.evaluate True \\\n",
    "test.visrank True \\\n",
    "data.save_dir \"result/log_ep200_coljit_triplet\" \\\n",
    "loss.name \"triplet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n",
      "Successfully loaded imagenet pretrained weights from \"/home/ntphat/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Successfully loaded pretrained weights from \"log/log_ep200_coljit_triplet/log/osnetx10_market_200ep_colorjitter_triplet/model/model.pth.tar-200\"\n",
      "Visualizing activation maps for market1501 ...\n",
      "- done batch 10/34\n",
      "- done batch 20/34\n",
      "- done batch 30/34\n"
     ]
    }
   ],
   "source": [
    "# Visualize activation map\n",
    "!python tools/visualize_actmap.py \\\n",
    "--root \"datasets\" \\\n",
    "--save-dir \"result/log_ep200_coljit_triplet\" \\\n",
    "--weights $WEIGHT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}